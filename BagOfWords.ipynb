{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from scipy.stats import multivariate_normal \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2800)\n"
     ]
    }
   ],
   "source": [
    "root = os.getcwd()\n",
    "train_folder = os.path.join(root,r\"D:\\PYTHON_PROJECTS\\GitHubProjects\\BagOfWordsAndHMMClassification\\textures\")\n",
    "train_files = os.listdir(train_folder)\n",
    "data_arr = []\n",
    "for i in range(len(train_files)):\n",
    "    file = os.path.join(train_folder,train_files[i])\n",
    "    image_array = mpimg.imread(file)\n",
    "    image_patches = extract_patches_2d(image_array, (7, 7), max_patches = 100)\n",
    "    for j in range(len(image_patches)):\n",
    "        patch_vec = np.ravel(image_patches[j])\n",
    "        data_arr.append(patch_vec)\n",
    "data_arr = np.matrix(data_arr)\n",
    "print(data_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "K = 3 ## K is the number of clusters that we want to create \n",
    "label_arr = np.zeros(data_arr.shape[0])\n",
    "for i in range(len(label_arr)):\n",
    "    label_arr[i] = np.random.choice(K)\n",
    "print(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(vec1,vec2):\n",
    "    \n",
    "    s1 = 0\n",
    "    \n",
    "    vec1 = np.ravel(vec1)\n",
    "    vec1 = vec1/np.linalg.norm(vec1)\n",
    "\n",
    "    vec2 = np.ravel(vec2)\n",
    "    vec2 = vec2/np.linalg.norm(vec2)\n",
    "    \n",
    "    L = len(vec1)\n",
    "    \n",
    "    for l in range(L):\n",
    "        diff = vec2[l]*vec1[l]\n",
    "        s1 = s1 + diff\n",
    "    sim = s1\n",
    "    \n",
    "    return(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_mean_cov(K,data_arr,label_arr):\n",
    "    mean_ls = [] ## List containing mean values of the clusters\n",
    "    cov_ls = []\n",
    "    size_ls = []\n",
    "    cluster_ls = [[] for k in range(K)] ## Create list of empty lists to store data belonging to a certain cluster\n",
    "    \n",
    "    for i in range(len(label_arr)):\n",
    "        for k in range(K):\n",
    "            if label_arr[i] == k:  ## if the label of the data at ith row is 'k'\n",
    "                norm_data = np.ravel(data_arr[i,:])/np.linalg.norm(np.ravel(data_arr[i,:]))\n",
    "                cluster_ls[k].append(norm_data) ## Fill the kth empty list with this data value                \n",
    "    \n",
    "    for k in range(K): \n",
    "        cluster_mat = np.matrix(cluster_ls[k])\n",
    "        pointNum = cluster_mat.shape[0]\n",
    "        cov_k = np.cov(cluster_mat.T)\n",
    "        mean_k = np.mean(cluster_mat,axis=0)\n",
    "        mean_k = np.ravel(mean_k)/np.linalg.norm(np.ravel(mean_k))\n",
    "        mean_ls.append(mean_k)\n",
    "        cov_ls.append(cov_k)\n",
    "        size_ls.append(pointNum)\n",
    "    return(mean_ls,cov_ls,size_ls)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_update(prev_mean,data_arr,label_arr):\n",
    "    for i in range(data_arr.shape[0]):\n",
    "        dist_ls = [] \n",
    "        for k in range(len(prev_mean)):\n",
    "            dist = similarity(data_arr[i,:],prev_mean[k]) ## Calculate the similarity of the ith datapoint with the kth mean\n",
    "            dist_ls.append(dist) ## Put the distance values in a list\n",
    "        dist_arr = np.array(dist_ls) ## Convert it to a NumPy array\n",
    "        new_label = np.argmax(dist_arr) ##The new_label of the point is the one which is closest to the ith datapoint,i.e., it has maximum similarity\n",
    "        label_arr[i] = new_label ## Set the new label\n",
    "    return(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_from_label(K,prev_mean,prev_cov,prev_size,data_arr,label_arr):\n",
    "    cluster_ls = [[] for k in range(K)]  ## Create list of empty lists to store data belonging to a certain cluster\n",
    "    \n",
    "    for i in range(data_arr.shape[0]):\n",
    "        for k in range(K):\n",
    "            if label_arr[i] == k: ## if the label of the pixel at location [i,j] is 'k'\n",
    "                norm_data = np.ravel(data_arr[i,:])/np.linalg.norm(np.ravel(data_arr[i,:]))\n",
    "                cluster_ls[k].append(norm_data) ## Fill the kth empty list with this pixel value\n",
    "                    \n",
    "    for k in range(K):\n",
    "        if len(cluster_ls[k]) !=0:  ## Only update the means of those clusters which has received at least one new point, else retain the old mean value\n",
    "            cluster_mat = np.matrix(cluster_ls[k])\n",
    "            pointNum = cluster_mat.shape[0]\n",
    "            mean_k = np.mean(cluster_mat,axis=0)\n",
    "            cov_k = np.cov(cluster_mat.T)\n",
    "            mean_k = np.ravel(mean_k)/np.linalg.norm(np.ravel(mean_k))\n",
    "            prev_mean[k] = mean_k\n",
    "            prev_cov[k] = cov_k\n",
    "            prev_size[k] = pointNum\n",
    "    new_mean = prev_mean\n",
    "    new_cov = prev_cov\n",
    "    new_size = prev_size\n",
    "    return(new_mean,new_cov,new_size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SphericalKMeans(data_arr,label_arr,K,maxIter):\n",
    "    mean_old,cov_old,size_old = init_mean_cov(K,data_arr,label_arr)\n",
    "    for t in range(maxIter):\n",
    "        new_label_arr = label_update(mean_old,data_arr,label_arr)\n",
    "        mean_new,cov_new,size_new = mean_from_label(K,mean_old,cov_old,size_old,data_arr,new_label_arr)\n",
    "        label_arr = new_label_arr ## Update the label array\n",
    "        mean_old = mean_new ## Update the mean values\n",
    "        cov_old = cov_new\n",
    "        size_old = size_new\n",
    "        print(\"Iteration {} is complete during training!!\".format(t+1))\n",
    "    return(mean_new,cov_new,size_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (147,) (49,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-bbce0f26f6b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcov_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSphericalKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-d0358feea154>\u001b[0m in \u001b[0;36mSphericalKMeans\u001b[1;34m(data_arr, label_arr, K, maxIter)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mSphericalKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmean_old\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcov_old\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_mean_cov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mnew_label_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_old\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmean_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcov_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_from_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_old\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcov_old\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize_old\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_label_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-116264dec94a>\u001b[0m in \u001b[0;36minit_mean_cov\u001b[1;34m(K, data_arr, label_arr)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabel_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m## if the label of the data at ith row is 'k'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[0mnorm_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mcluster_ls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## Fill the kth empty list with this data value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aksha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2474\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2475\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2476\u001b[1;33m                 \u001b[0msqnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2477\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2478\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (147,) (49,) "
     ]
    }
   ],
   "source": [
    "mean_new,cov_new,size_new = SphericalKMeans(data_arr,label_arr,K,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63956044 0.17923077 0.18120879]\n"
     ]
    }
   ],
   "source": [
    "prior_ls = size_new/np.sum(size_new)\n",
    "print(prior_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testImage(img_file,mean_new,cov_new,prior_ls):\n",
    "    img_arr = mpimg.imread(img_file)\n",
    "    img_patches = extract_patches_2d(img_arr, (7, 7), max_patches = 50)\n",
    "    test_arr = []\n",
    "    for i in range(len(img_patches)):\n",
    "        patch_vec = np.ravel(img_patches[i])\n",
    "        test_arr.append(patch_vec)\n",
    "    test_arr = np.matrix(test_arr)\n",
    "    print(test_arr.shape)\n",
    "    for j in range(test_arr.shape[0]):\n",
    "        feat_vec = []\n",
    "        for k in range(len(size_new)):\n",
    "            var = multivariate_normal(mean = mean_new[k],cov = cov_new[k])\n",
    "            test1 = np.ravel(test_arr[j,:])\n",
    "            test_sample = test1/np.linalg.norm(test1)\n",
    "            lkl = var.pdf(test_sample)\n",
    "            post = lkl*prior_ls[k]\n",
    "            feat_vec.append(post)\n",
    "        print(feat_vec/sum(feat_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raffia.000.tiff\n",
      "(50, 49)\n",
      "[1.00000000e+00 1.59832995e-12 2.94264930e-13]\n",
      "[9.99999999e-01 9.00599552e-10 2.79639004e-13]\n",
      "[1.00000000e+00 4.20704365e-11 2.16376916e-10]\n",
      "[9.99999997e-01 3.20600658e-09 1.46924398e-11]\n",
      "[9.99999304e-01 1.00224966e-07 5.96104846e-07]\n",
      "[1.00000000e+00 3.12057005e-16 3.30630517e-10]\n",
      "[9.99999993e-01 6.98877846e-09 2.23079602e-12]\n",
      "[1.00000000e+00 5.67671559e-13 1.17411111e-11]\n",
      "[1.00000000e+00 4.83487029e-12 3.23440015e-12]\n",
      "[1.00000000e+00 2.15135242e-16 2.34970344e-11]\n",
      "[1.00000000e+00 4.60339281e-11 6.13438250e-11]\n",
      "[1.00000000e+00 4.72353289e-17 1.03010023e-10]\n",
      "[9.99999999e-01 3.36901644e-14 1.20750523e-09]\n",
      "[9.99999994e-01 2.99018099e-11 6.00015637e-09]\n",
      "[1.00000000e+00 6.92402705e-15 7.79539584e-11]\n",
      "[9.99999996e-01 5.28660093e-10 3.80323895e-09]\n",
      "[1.00000000e+00 1.96366989e-12 9.81178305e-11]\n",
      "[9.99999996e-01 3.37680688e-13 4.07357467e-09]\n",
      "[9.99999999e-01 7.56526527e-10 5.38240921e-13]\n",
      "[9.99999998e-01 1.97241075e-09 1.27156996e-11]\n",
      "[1.00000000e+00 1.98683957e-12 1.17051027e-10]\n",
      "[1.00000000e+00 3.11314152e-11 3.54501138e-10]\n",
      "[1.00000000e+00 1.98563976e-10 3.66946624e-12]\n",
      "[1.00000000e+00 1.78736154e-10 1.72582373e-10]\n",
      "[1.00000000e+00 2.23533764e-11 8.21347872e-13]\n",
      "[9.99999983e-01 1.41627838e-12 1.73121147e-08]\n",
      "[9.99999998e-01 2.37745497e-10 1.60184163e-09]\n",
      "[9.99999998e-01 2.19141900e-09 1.99058947e-11]\n",
      "[1.00000000e+00 7.43690668e-12 2.74867734e-14]\n",
      "[1.00000000e+00 2.12407528e-14 2.05945616e-10]\n",
      "[1.00000000e+00 6.55309697e-12 2.16284731e-12]\n",
      "[1.00000000e+00 3.31088190e-14 4.58537532e-12]\n",
      "[1.00000000e+00 4.71181710e-14 2.73503484e-11]\n",
      "[1.00000000e+00 4.24625963e-11 1.39108502e-12]\n",
      "[9.99931525e-01 6.84744978e-05 9.47464212e-11]\n",
      "[1.00000000e+00 1.29418815e-12 2.90968553e-13]\n",
      "[1.00000000e+00 7.25148814e-11 1.25198367e-11]\n",
      "[1.00000000e+00 6.29121393e-13 4.22157864e-10]\n",
      "[9.99999808e-01 1.10509548e-10 1.91869932e-07]\n",
      "[1.00000000e+00 6.24602714e-11 3.88045935e-13]\n",
      "[1.00000000e+00 3.83275446e-10 2.21350612e-11]\n",
      "[1.00000000e+00 5.31787943e-11 2.08797105e-12]\n",
      "[1.00000000e+00 1.81033399e-12 6.34887455e-12]\n",
      "[1.00000000e+00 4.03179942e-11 3.05040656e-13]\n",
      "[1.00000000e+00 1.38799786e-11 4.38240628e-12]\n",
      "[1.00000000e+00 4.05595566e-12 3.25200997e-11]\n",
      "[1.00000000e+00 1.74169416e-12 3.83855453e-13]\n",
      "[9.99999962e-01 2.72229788e-12 3.84412683e-08]\n",
      "[9.99999964e-01 3.58950620e-08 5.56870241e-11]\n",
      "[1.00000000e+00 4.65543935e-13 9.66801275e-11]\n"
     ]
    }
   ],
   "source": [
    "test_folder = os.path.join(root,r\"D:\\PYTHON_PROJECTS\\GitHubProjects\\BagOfWordsAndHMMClassification\\textures\")\n",
    "img_files = os.listdir(test_folder)\n",
    "fileName = random.choice(img_files)\n",
    "print(fileName)\n",
    "filePath = os.path.join(test_folder,fileName)\n",
    "testImage(filePath,mean_new,cov_new,prior_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
